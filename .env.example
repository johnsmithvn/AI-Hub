# Environment Configuration
DEBUG=True
HOST=127.0.0.1
PORT=8000

# Database Configuration
DATABASE_URL=postgresql+asyncpg://postgres:password@localhost:5432/ai_hub
DATABASE_ECHO=False

# Redis Configuration
REDIS_URL=redis://localhost:6379/0
REDIS_MAX_CONNECTIONS=20

# Model Management
MODEL_CACHE_DIR=./models
MAX_VRAM_GB=14.0
MODEL_LOAD_TIMEOUT=300
CONCURRENT_MODELS=2

# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_TIMEOUT=120

# HuggingFace Configuration
HF_TOKEN=your_huggingface_token_here
HF_CACHE_DIR=./hf_cache

# Training Configuration
TRAINING_DATA_DIR=./training_data
TRAINING_OUTPUT_DIR=./trained_models
MAX_TRAINING_JOBS=2

# Multi-Modal Configuration
UPLOAD_DIR=./uploads
MAX_FILE_SIZE=104857600

# API Security
SECRET_KEY=your-secret-key-change-in-production-please-use-strong-key
ACCESS_TOKEN_EXPIRE_MINUTES=1440
API_KEY=your-api-key-here

# CORS Configuration (add your frontend URLs)
CORS_ORIGINS=["http://localhost:3000","http://localhost:8080","http://localhost:5173"]

# Background Tasks
CELERY_BROKER_URL=redis://localhost:6379/1
CELERY_RESULT_BACKEND=redis://localhost:6379/1

# Monitoring
ENABLE_METRICS=True
METRICS_PORT=8001
LOG_LEVEL=INFO

# Performance
MAX_WORKERS=4
WORKER_CONNECTIONS=1000

# Model-Specific Settings
DEFAULT_MODEL=llama2:7b
CODE_MODEL=codellama:7b
VISION_MODEL=llava:7b

# Device Configuration
DEVICE=auto
TORCH_DTYPE=float16
