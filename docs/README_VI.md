# ğŸ¤– AI Backend Hub - HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng HoÃ n Chá»‰nh

## ğŸ“‹ Má»¥c Lá»¥c
1. [Tá»•ng Quan Há»‡ Thá»‘ng](#tá»•ng-quan-há»‡-thá»‘ng)
2. [Kiáº¿n TrÃºc Tá»•ng Thá»ƒ](#kiáº¿n-trÃºc-tá»•ng-thá»ƒ)
3. [CÃ¡c Bug ÄÃ£ Sá»­a](#cÃ¡c-bug-Ä‘Ã£-sá»­a)
4. [CÃ¡ch Thá»©c Hoáº¡t Äá»™ng](#cÃ¡ch-thá»©c-hoáº¡t-Ä‘á»™ng)
5. [HÆ°á»›ng Dáº«n CÃ i Äáº·t](#hÆ°á»›ng-dáº«n-cÃ i-Ä‘áº·t)
6. [HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng](#hÆ°á»›ng-dáº«n-sá»­-dá»¥ng)
7. [API Documentation](#api-documentation)
8. [Troubleshooting](#troubleshooting)

---

## ğŸ¯ Tá»•ng Quan Há»‡ Thá»‘ng

**AI Backend Hub** lÃ  má»™t há»‡ thá»‘ng backend hoÃ n chá»‰nh Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c á»©ng dá»¥ng AI tiÃªn tiáº¿n vá»›i kháº£ nÄƒng:

### âœ¨ TÃ­nh NÄƒng ChÃ­nh
- **ğŸ”„ Quáº£n lÃ½ Model Äá»™ng**: Tá»± Ä‘á»™ng chuyá»ƒn Ä‘á»•i giá»¯a cÃ¡c AI models dá»±a trÃªn yÃªu cáº§u
- **ğŸ® Multi-Modal**: Há»— trá»£ text, hÃ¬nh áº£nh, Ã¢m thanh vÃ  video
- **ğŸ”§ Custom Training**: Fine-tune models vá»›i dá»¯ liá»‡u riÃªng (LoRA/QLoRA)
- **âš¡ Performance Optimization**: Tá»‘i Æ°u cho RTX 4060 Ti 16GB
- **ğŸ“Š Real-time Monitoring**: Theo dÃµi hiá»‡u suáº¥t vÃ  tÃ i nguyÃªn
- **ğŸ”’ Production Ready**: Báº£o máº­t, scalable vÃ  reliable

---

## ğŸ—ï¸ Kiáº¿n TrÃºc Tá»•ng Thá»ƒ

```
AI Backend Hub
â”œâ”€â”€ ğŸŒ FastAPI Web Framework
â”œâ”€â”€ ğŸ—„ï¸ PostgreSQL + pgvector (Vector Database)
â”œâ”€â”€ ğŸ”´ Redis (Caching & Sessions)
â”œâ”€â”€ ğŸ¤– Ollama (Local LLM Serving)
â”œâ”€â”€ ğŸ§  HuggingFace Integration
â”œâ”€â”€ ğŸ³ Docker Container Support
â””â”€â”€ ğŸ“Š Prometheus Monitoring
```

### ğŸ“ Cáº¥u TrÃºc Project
```
AI hub/
â”œâ”€â”€ src/                        # Source code chÃ­nh
â”‚   â”œâ”€â”€ core/                   # Dá»‹ch vá»¥ cá»‘t lÃµi
â”‚   â”‚   â”œâ”€â”€ config.py          # Cáº¥u hÃ¬nh há»‡ thá»‘ng
â”‚   â”‚   â”œâ”€â”€ database.py        # Káº¿t ná»‘i database
â”‚   â”‚   â”œâ”€â”€ model_manager.py   # Quáº£n lÃ½ AI models
â”‚   â”‚   â””â”€â”€ redis_client.py    # Káº¿t ná»‘i Redis
â”‚   â”œâ”€â”€ models/                # Database models
â”‚   â”‚   â”œâ”€â”€ user.py           # User management
â”‚   â”‚   â”œâ”€â”€ conversation.py   # Chat conversations
â”‚   â”‚   â”œâ”€â”€ training.py       # Training jobs
â”‚   â”‚   â””â”€â”€ analytics.py      # System analytics
â”‚   â”œâ”€â”€ schemas/              # API schemas
â”‚   â”‚   â”œâ”€â”€ chat.py          # Chat API schemas
â”‚   â”‚   â””â”€â”€ models.py        # Model API schemas
â”‚   â””â”€â”€ api/                 # API endpoints
â”‚       â””â”€â”€ v1/endpoints/    # Version 1 API
â”‚           â”œâ”€â”€ chat.py      # Chat endpoints
â”‚           â”œâ”€â”€ models.py    # Model management
â”‚           â”œâ”€â”€ training.py  # Training endpoints
â”‚           â””â”€â”€ health.py    # Health checks
â”œâ”€â”€ .env                     # Environment variables
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ docker-compose.yml       # Docker configuration
â””â”€â”€ main.py                 # Application entry point
```

---

## ğŸ”§ CÃ¡c Bug ÄÃ£ Sá»­a

### 1. **Database Import Issues**
- **Lá»—i**: Wildcard imports vÃ  type hints khÃ´ng Ä‘Ãºng
- **Sá»­a**: Chuyá»ƒn sang explicit imports vÃ  AsyncGenerator type hints
- **File**: `src/core/database.py`

### 2. **Missing Imports**
- **Lá»—i**: Thiáº¿u `asyncio`, `torch`, `GPUtil` imports
- **Sá»­a**: ThÃªm missing imports vÃ  cÃ i Ä‘áº·t packages thiáº¿u
- **File**: `src/api/v1/endpoints/chat.py`, `requirements.txt`

### 3. **Model Structure Issues**
- **Lá»—i**: SQLAlchemy reserved keyword `metadata`
- **Sá»­a**: Äá»•i tÃªn thÃ nh `extra_data`
- **File**: `src/models/conversation.py`, `src/models/analytics.py`

### 4. **Import Path Conflicts**
- **Lá»—i**: Relative import issues trong test files
- **Sá»­a**: Sá»­ dá»¥ng absolute imports vÃ  Ä‘áº·t PYTHONPATH Ä‘Ãºng
- **File**: Táº¥t cáº£ model files

### 5. **Missing Methods**
- **Lá»—i**: ModelManager thiáº¿u method `generate_response`
- **Sá»­a**: ThÃªm method hoÃ n chá»‰nh vá»›i Ollama vÃ  HuggingFace support
- **File**: `src/core/model_manager.py`

---

## âš™ï¸ CÃ¡ch Thá»©c Hoáº¡t Äá»™ng

### ğŸ”„ Luá»“ng Xá»­ LÃ½ Chat
```
User Request â†’ FastAPI â†’ Model Manager â†’ AI Model â†’ Response
     â†“
Database (Conversation History) â† Redis (Caching)
```

#### Chi Tiáº¿t:
1. **Request Processing**: FastAPI nháº­n request tá»« client
2. **Model Selection**: ModelManager chá»n model phÃ¹ há»£p nháº¥t
3. **Resource Management**: Kiá»ƒm tra VRAM vÃ  load/unload models
4. **Generation**: Gá»i Ollama hoáº·c HuggingFace Ä‘á»ƒ generate response
5. **Caching**: LÆ°u vÃ o Redis Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™
6. **Database**: LÆ°u conversation history vÃ o PostgreSQL
7. **Monitoring**: Ghi nháº­n metrics vÃ o Analytics

### ğŸ§  Intelligent Model Management
```python
# ModelManager tá»± Ä‘á»™ng:
1. PhÃ¢n tÃ­ch yÃªu cáº§u (text, code, multimodal)
2. Chá»n model tá»‘i Æ°u dá»±a trÃªn:
   - Task type (coding, chat, vision)
   - Available VRAM
   - Model performance history
   - User preferences
3. Load/unload models Ä‘á»ƒ tá»‘i Æ°u memory
4. Cache frequently used models
```

### ğŸ“Š Performance Monitoring
- **Real-time Metrics**: CPU, GPU, Memory usage
- **Response Time Tracking**: Theo dÃµi latency cá»§a tá»«ng model
- **Error Rate Monitoring**: PhÃ¡t hiá»‡n vÃ  xá»­ lÃ½ lá»—i
- **Usage Analytics**: Thá»‘ng kÃª sá»­ dá»¥ng cá»§a users

---

## ğŸš€ HÆ°á»›ng Dáº«n CÃ i Äáº·t

### BÆ°á»›c 1: CÃ i Äáº·t Dependencies
```bash
# 1. CÃ i Ä‘áº·t PostgreSQL vá»›i pgvector
# Windows: Download tá»« https://www.postgresql.org/download/windows/
# Sau khi cÃ i xong, enable pgvector extension

# 2. CÃ i Ä‘áº·t Redis
# Windows: Download tá»« https://redis.io/download

# 3. CÃ i Ä‘áº·t Ollama
# Download tá»« https://ollama.ai/
```

### BÆ°á»›c 2: Khá»Ÿi Äá»™ng Dá»± Ãn
```powershell
# Di chuyá»ƒn vÃ o thÆ° má»¥c project
cd "d:\DEV\All-Project\AI\AI hub"

# KÃ­ch hoáº¡t virtual environment
& "D:/DEV/All-Project/AI/AI hub/.venv/Scripts/Activate.ps1"

# Cháº¡y database migrations
alembic upgrade head

# Pull cÃ¡c AI models
ollama pull llama2:7b
ollama pull codellama:7b
ollama pull llava:7b

# Khá»Ÿi Ä‘á»™ng á»©ng dá»¥ng
python main.py
```

### BÆ°á»›c 3: XÃ¡c Minh Hoáº¡t Äá»™ng
```powershell
# Kiá»ƒm tra health cá»§a há»‡ thá»‘ng
curl http://localhost:8000/health

# Xem API documentation
# Má»Ÿ browser: http://localhost:8000/docs
```

---

## ğŸ“– HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng

### ğŸ’¬ Chat API

#### Gá»­i tin nháº¯n Ä‘Æ¡n giáº£n:
```bash
curl -X POST "http://localhost:8000/api/v1/chat/completions" \
-H "Content-Type: application/json" \
-d '{
  "messages": [
    {"role": "user", "content": "Xin chÃ o! Báº¡n cÃ³ thá»ƒ giÃºp tÃ´i code Python khÃ´ng?"}
  ],
  "model": "codellama:7b",
  "stream": false
}'
```

#### Streaming Response:
```bash
curl -X POST "http://localhost:8000/api/v1/chat/completions" \
-H "Content-Type: application/json" \
-d '{
  "messages": [
    {"role": "user", "content": "Viáº¿t má»™t hÃ m Python Ä‘á»ƒ sáº¯p xáº¿p máº£ng"}
  ],
  "model": "codellama:7b",
  "stream": true
}'
```

### ğŸ¤– Model Management

#### Xem danh sÃ¡ch models:
```bash
curl http://localhost:8000/api/v1/models
```

#### Load má»™t model:
```bash
curl -X POST "http://localhost:8000/api/v1/models/load" \
-H "Content-Type: application/json" \
-d '{
  "model_id": "llama2:7b",
  "force_reload": false
}'
```

#### Kiá»ƒm tra status models:
```bash
curl http://localhost:8000/api/v1/models/status
```

### ğŸ“ Custom Training

#### Báº¯t Ä‘áº§u training job:
```bash
curl -X POST "http://localhost:8000/api/v1/training/jobs" \
-H "Content-Type: application/json" \
-d '{
  "name": "My Custom Model",
  "base_model": "llama2:7b",
  "dataset_path": "/path/to/training/data.json",
  "training_type": "lora",
  "learning_rate": 2e-4,
  "num_epochs": 3
}'
```

#### Theo dÃµi training progress:
```bash
curl http://localhost:8000/api/v1/training/jobs/{job_id}/status
```

---

## ğŸ“š API Documentation

### Chat Endpoints
- `POST /api/v1/chat/completions` - Gá»­i tin nháº¯n chat
- `GET /api/v1/chat/conversations` - Láº¥y danh sÃ¡ch conversations
- `DELETE /api/v1/chat/conversations/{id}` - XÃ³a conversation

### Model Endpoints  
- `GET /api/v1/models` - Danh sÃ¡ch táº¥t cáº£ models
- `POST /api/v1/models/load` - Load model vÃ o memory
- `POST /api/v1/models/unload` - Unload model khá»i memory
- `GET /api/v1/models/status` - Tráº¡ng thÃ¡i system vÃ  models

### Training Endpoints
- `POST /api/v1/training/jobs` - Táº¡o training job má»›i
- `GET /api/v1/training/jobs` - Danh sÃ¡ch training jobs
- `GET /api/v1/training/jobs/{id}` - Chi tiáº¿t training job
- `DELETE /api/v1/training/jobs/{id}` - Há»§y training job

### Health & Monitoring
- `GET /health` - Health check tá»•ng thá»ƒ
- `GET /api/v1/system/metrics` - System metrics
- `GET /api/v1/system/analytics` - Usage analytics

---

## ğŸ› ï¸ Troubleshooting

### Váº¥n Äá» ThÆ°á»ng Gáº·p

#### 1. Models khÃ´ng load Ä‘Æ°á»£c
```bash
# Kiá»ƒm tra Ollama service
ollama list

# Restart Ollama
ollama serve

# Kiá»ƒm tra VRAM
nvidia-smi
```

#### 2. Database connection lá»—i
```bash
# Kiá»ƒm tra PostgreSQL
pg_isready -h localhost -p 5432

# Kiá»ƒm tra pgvector extension
psql -d ai_hub -c "CREATE EXTENSION IF NOT EXISTS vector;"
```

#### 3. Redis connection issues
```bash
# Kiá»ƒm tra Redis
redis-cli ping

# Restart Redis service
net start redis
```

#### 4. Out of Memory (OOM)
```python
# Trong config, giáº£m sá»‘ models Ä‘Æ°á»£c load cÃ¹ng lÃºc
MAX_CONCURRENT_MODELS = 1
MODEL_UNLOAD_TIMEOUT = 300  # 5 minutes
```

### Logs vÃ  Debugging
```bash
# Xem logs real-time
tail -f logs/app.log

# Check GPU memory
nvidia-smi --query-gpu=memory.used,memory.total --format=csv

# Monitor system resources
htop
```

---

## ğŸ‰ Káº¿t Luáº­n

**AI Backend Hub** giá» Ä‘Ã¢y Ä‘Ã£ sáºµn sÃ ng Ä‘á»ƒ phá»¥c vá»¥ cÃ¡c á»©ng dá»¥ng AI production-level vá»›i:

âœ… **Táº¥t cáº£ bugs Ä‘Ã£ Ä‘Æ°á»£c fix**
âœ… **Architecture hoÃ n chá»‰nh vÃ  scalable**  
âœ… **Resource optimization cho RTX 4060 Ti**
âœ… **Multi-modal AI capabilities**
âœ… **Production monitoring vÃ  logging**
âœ… **Comprehensive API documentation**

### ğŸš€ Next Steps
1. **Deploy lÃªn production** vá»›i Docker/Kubernetes
2. **ThÃªm authentication & authorization**
3. **Integrate vá»›i frontend applications**
4. **Scale horizontal vá»›i load balancing**
5. **Add more AI models vÃ  capabilities**

**Happy Coding! ğŸŠ**
