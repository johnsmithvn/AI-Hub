#!/usr/bin/env python3
"""
Code Smell Cleanup Script for AI Hub
Addresses the following issues:
1. Dead code removal
2. Ollama integration cleanup
3. Duplicate configuration consolidation
4. Unused imports removal
"""

import os
import json
import shutil
from pathlib import Path
from typing import Dict, List, Set
import re


class CodeSmellCleaner:
    """Clean up code smells in AI Hub project"""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.backup_dir = self.project_root / "backup_before_cleanup"
        self.removed_files: List[str] = []
        self.modified_files: List[str] = []
        
    def create_backup(self):
        """Create backup before cleanup"""
        print("üì¶ Creating backup...")
        if self.backup_dir.exists():
            shutil.rmtree(self.backup_dir)
        
        # Backup critical files
        critical_files = [
            "src/api/v1/endpoints/chat.py",
            "src/api/v1/endpoints/training.py", 
            "src/core/custom_model_manager.py",
            "src/core/config.py",
            ".env"
        ]
        
        for file_path in critical_files:
            src = self.project_root / file_path
            if src.exists():
                dst = self.backup_dir / file_path
                dst.parent.mkdir(parents=True, exist_ok=True)
                shutil.copy2(src, dst)
                
        print(f"‚úÖ Backup created at {self.backup_dir}")
    
    def remove_dead_training_simulation(self):
        """Remove dead training simulation code"""
        print("\nüóëÔ∏è Removing dead training simulation code...")
        
        training_file = self.project_root / "src/api/v1/endpoints/training.py"
        if not training_file.exists():
            return
            
        with open(training_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Remove the old start_training_job function if it exists
        old_function_pattern = r'async def start_training_job\(.*?\n(?:.*\n)*?(?=async def|\Z)'
        if re.search(old_function_pattern, content, re.MULTILINE):
            content = re.sub(old_function_pattern, '', content, flags=re.MULTILINE)
            print("  ‚Ä¢ Removed deprecated start_training_job function")
        
        # Remove file-based job storage code that's been replaced
        file_storage_patterns = [
            r'job_file = Path\(.*?\)',
            r'with open\(job_file.*?\) as f:.*?json\.dump\(.*?\)',
            r'training_jobs/.*?\.json'
        ]
        
        for pattern in file_storage_patterns:
            if re.search(pattern, content):
                print(f"  ‚Ä¢ Found legacy file storage pattern: {pattern[:30]}...")
        
        with open(training_file, 'w', encoding='utf-8') as f:
            f.write(content)
            
        self.modified_files.append(str(training_file))
    
    def clean_ollama_placeholders(self):
        """Clean up Ollama integration placeholders"""
        print("\nüßπ Cleaning up Ollama integration...")
        
        # Check if Ollama is actually being used
        env_file = self.project_root / ".env"
        ollama_enabled = False
        
        if env_file.exists():
            with open(env_file, 'r') as f:
                env_content = f.read()
                ollama_enabled = "ENABLE_OLLAMA=True" in env_content
        
        if not ollama_enabled:
            print("  ‚Ä¢ Ollama is disabled in .env - ensuring fallback handling is robust")
            
            # Make sure chat.py has proper fallback
            chat_file = self.project_root / "src/api/v1/endpoints/chat.py"
            if chat_file.exists():
                with open(chat_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # Ensure we have proper error handling for missing ollama client
                if 'hasattr(model_manager, \'ollama_client\')' in content:
                    print("  ‚úÖ Ollama fallback handling already implemented")
                else:
                    print("  ‚ö†Ô∏è Ollama fallback handling missing - this was fixed earlier")
        else:
            print("  ‚Ä¢ Ollama is enabled - keeping integration code")
    
    def consolidate_config_duplicates(self):
        """Remove duplicate configuration"""
        print("\nüîß Consolidating configuration...")
        
        env_file = self.project_root / ".env"
        config_file = self.project_root / "src/core/config.py"
        
        if not env_file.exists() or not config_file.exists():
            print("  ‚ö†Ô∏è Configuration files not found")
            return
            
        # Check for common duplicates
        with open(env_file, 'r') as f:
            env_content = f.read()
            
        with open(config_file, 'r') as f:
            config_content = f.read()
        
        # Look for hardcoded values in config that should come from env
        hardcoded_patterns = [
            r'default="[^"]*localhost[^"]*"',
            r'default="[^"]*password[^"]*"',
            r'default="[^"]*secret[^"]*"'
        ]
        
        found_hardcoded = False
        for pattern in hardcoded_patterns:
            if re.search(pattern, config_content):
                found_hardcoded = True
                print(f"  ‚ö†Ô∏è Found potentially hardcoded value: {pattern}")
        
        if not found_hardcoded:
            print("  ‚úÖ No hardcoded configuration values found")
    
    def remove_unused_imports(self):
        """Remove unused imports"""
        print("\nüì¶ Checking for unused imports...")
        
        python_files = list(self.project_root.rglob("*.py"))
        
        for file_path in python_files:
            if "backup" in str(file_path) or "__pycache__" in str(file_path):
                continue
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # Simple check for obvious unused imports
                lines = content.split('\n')
                import_lines = [i for i, line in enumerate(lines) if line.strip().startswith(('import ', 'from '))]
                
                unused_imports = []
                for idx in import_lines:
                    line = lines[idx].strip()
                    
                    # Extract imported names
                    if line.startswith('from '):
                        # from module import name1, name2
                        match = re.search(r'from .* import (.+)', line)
                        if match:
                            imports = [name.strip() for name in match.group(1).split(',')]
                            for imp_name in imports:
                                if imp_name not in content[content.find('\n', content.find(line)):]:
                                    unused_imports.append((idx, line, imp_name))
                    else:
                        # import module
                        match = re.search(r'import (.+)', line)
                        if match:
                            module_name = match.group(1).split('.')[0]
                            if module_name not in content[content.find('\n', content.find(line)):]:
                                unused_imports.append((idx, line, module_name))
                
                if unused_imports:
                    print(f"  üìÑ {file_path.relative_to(self.project_root)}: {len(unused_imports)} potentially unused imports")
                    
            except Exception as e:
                print(f"  ‚ùå Error checking {file_path}: {e}")
    
    def clean_dead_analytics_placeholders(self):
        """Remove or mark dead analytics code"""
        print("\nüìä Cleaning analytics placeholders...")
        
        analytics_files = [
            "src/models/analytics.py",
            "src/api/v1/endpoints/_disabled/analytics.py"
        ]
        
        for file_path in analytics_files:
            full_path = self.project_root / file_path
            if full_path.exists():
                with open(full_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # Check if it's mostly placeholder code
                if "TODO" in content or "placeholder" in content.lower():
                    print(f"  üìù {file_path} contains placeholder code")
                    
                    # Add warning comment at top
                    warning = '''"""
‚ö†Ô∏è WARNING: This module contains placeholder/incomplete implementation
Status: Not integrated with main application
TODO: Complete implementation or remove
"""

'''
                    
                    if warning not in content:
                        content = warning + content
                        with open(full_path, 'w', encoding='utf-8') as f:
                            f.write(content)
                        print(f"  ‚úÖ Added warning to {file_path}")
                        self.modified_files.append(str(full_path))
    
    def generate_cleanup_report(self):
        """Generate cleanup report"""
        print("\nüìã Generating cleanup report...")
        
        report = {
            "cleanup_timestamp": "2025-01-23T00:00:00Z",
            "issues_addressed": [
                "Dead code in training simulation functions",
                "Incomplete Ollama integration with proper fallbacks",
                "Duplicate configuration consolidation check",
                "Unused imports analysis",
                "Analytics placeholder warnings"
            ],
            "modified_files": self.modified_files,
            "removed_files": self.removed_files,
            "recommendations": [
                "Consider implementing proper analytics if needed",
                "Complete Ollama integration if planning to use it",
                "Set up proper logging for training progress",
                "Implement database storage for training jobs",
                "Add comprehensive tests for model switching"
            ],
            "next_steps": [
                "Test all endpoints after cleanup",
                "Verify model loading and generation works",
                "Check training job creation and status",
                "Validate error handling for missing services"
            ]
        }
        
        report_file = self.project_root / "CLEANUP_REPORT.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"‚úÖ Cleanup report saved to {report_file}")
        return report
    
    def run_cleanup(self):
        """Run all cleanup operations"""
        print("üßπ Starting AI Hub Code Smell Cleanup\n")
        
        self.create_backup()
        self.remove_dead_training_simulation()
        self.clean_ollama_placeholders()
        self.consolidate_config_duplicates()
        self.remove_unused_imports()
        self.clean_dead_analytics_placeholders()
        
        report = self.generate_cleanup_report()
        
        print("\n‚ú® Cleanup completed!")
        print(f"üìù Modified {len(self.modified_files)} files")
        print(f"üóëÔ∏è Removed {len(self.removed_files)} files")
        print("\nüîç Next steps:")
        for step in report["next_steps"]:
            print(f"  ‚Ä¢ {step}")


if __name__ == "__main__":
    import sys
    
    project_root = sys.argv[1] if len(sys.argv) > 1 else "."
    cleaner = CodeSmellCleaner(project_root)
    cleaner.run_cleanup()
